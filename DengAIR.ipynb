{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(zoo)\n",
    "library(dplyr)\n",
    "library(\"scales\")\n",
    "library(glmnet)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv data\n",
    "df_train_features <- read.csv(file=\"dengue_features_train.csv\")\n",
    "\n",
    "df_train_labels <- read.csv(file=\"dengue_labels_train.csv\")\n",
    "\n",
    "df_test_features <- read.csv(file=\"dengue_features_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop week_start_date colum\n",
    "\n",
    "df_train_features$week_start_date <- NULL\n",
    "df_train_labels$week_start_date <- NULL\n",
    "\n",
    "#change Kelvin Columns to Celcius\n",
    "df_train_features$reanalysis_min_air_temp_k <- (df_train_features$reanalysis_min_air_temp_k - 273.15)\n",
    "\n",
    "df_train_features$reanalysis_max_air_temp_k <- (df_train_features$reanalysis_max_air_temp_k - 273.15)\n",
    "\n",
    "df_train_features$reanalysis_dew_point_temp_k <- (df_train_features$reanalysis_dew_point_temp_k - 273.15)\n",
    "\n",
    "df_train_features$reanalysis_air_temp_k <- (df_train_features$reanalysis_air_temp_k - 273.15)\n",
    "\n",
    "#split the data by city\n",
    "\n",
    "df_train_features_sj <- subset(df_train_features, subset=city=='sj')\n",
    "df_train_features_iq <- subset(df_train_features, subset=city=='iq')\n",
    "\n",
    "df_train_labels_sj <- subset(df_train_labels, subset=city=='sj')\n",
    "df_train_labels_iq <- subset(df_train_labels, subset=city=='iq')\n",
    "\n",
    "#drop city column\n",
    "\n",
    "df_train_features_sj <- dplyr::select(df_train_features_sj, -city)\n",
    "df_train_features_iq <- dplyr::select(df_train_features_iq, -city)\n",
    "\n",
    "#fill null values with the mean value of the column\n",
    "df_train_features_sj = na.aggregate(df_train_features_sj)\n",
    "df_train_features_iq = na.aggregate(df_train_features_iq)\n",
    "\n",
    "#drop the correlating features for the San Juan training data\n",
    "df_train_features_sj <- dplyr::select(df_train_features_sj, -reanalysis_avg_temp_k)\n",
    "df_train_features_sj <- dplyr::select(df_train_features_sj, -reanalysis_sat_precip_amt_mm)\n",
    "df_train_features_sj <- dplyr::select(df_train_features_sj, -reanalysis_specific_humidity_g_per_kg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data in range from 0 to 1\n",
    "df_train_features_sj <- apply(df_train_features_sj, MARGIN = 2, FUN = function(X) (X - min(X))/diff(range(X)))\n",
    "df_train_features_iq <- apply(df_train_features_iq, MARGIN = 2, FUN = function(X) (X - min(X))/diff(range(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- as.matrix(df_train_features_sj)\n",
    "y <- as.matrix(as.matrix(df_train_labels_sj[, 4])) \n",
    "\n",
    "\n",
    "## 75% of the sample size\n",
    "smp_size <- floor(0.75 * nrow(x))\n",
    "smp_size_y <- floor(0.75 * nrow(y))\n",
    "## set the seed to make your partition reproducible\n",
    "set.seed(1)\n",
    "train_ind <- sample(seq_len(nrow(x)), size = smp_size)\n",
    "train_ind_y <- sample(seq_len(nrow(y)), size = smp_size_y)\n",
    " \n",
    "x_train <- x[train_ind, ]\n",
    "x_test <- x[-train_ind, ]\n",
    "\n",
    "y_train <- y[train_ind_y, ]\n",
    "y_test <- y[-train_ind_y, ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5.3796435018809"
      ],
      "text/latex": [
       "5.3796435018809"
      ],
      "text/markdown": [
       "5.3796435018809"
      ],
      "text/plain": [
       "[1] 5.379644"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ridge regression\n",
    "\n",
    "set.seed(1)\n",
    "cv.out = cv.glmnet(x_train, y_train ,alpha = 0, type.measure = \"mae\") # Fit ridge regression model on training data\n",
    "bestlam = cv.out$lambda.min  # Select lamda that minimizes training MSE\n",
    "\n",
    "ridge_pred = predict(cv.out, s = bestlam, newx = x_test)\n",
    "\n",
    "\n",
    "mae <- function(error) return(mean(abs(error)) )\n",
    "\n",
    "score   <-  mae(y_test - ridge_pred)\n",
    "\n",
    "sqrt(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5.24171717312229"
      ],
      "text/latex": [
       "5.24171717312229"
      ],
      "text/markdown": [
       "5.24171717312229"
      ],
      "text/plain": [
       "[1] 5.241717"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ridge regression\n",
    "\n",
    "set.seed(1)\n",
    "cv.out = cv.glmnet(x, y, alpha = 1, type.measure = \"mae\") \n",
    " \n",
    "bestlam = cv.out$lambda.min  # Select lamda that minimizes training MSE\n",
    "\n",
    "lasso_pred = predict(cv.out, s = bestlam, newx = x_test)\n",
    "\n",
    "\n",
    "score   <-  mae(y_test - lasso_pred)\n",
    "sqrt(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mod= knnreg(x_train,y_train, k = 4)\n",
    "knn_pred = predict(knn_mod, newdata = x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
