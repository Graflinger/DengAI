{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(zoo)\n",
    "library(dplyr)\n",
    "library(\"scales\")\n",
    "library(glmnet)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv data\n",
    "df_train_features <- read.csv(file=\"dengue_features_train.csv\")\n",
    "\n",
    "df_train_labels <- read.csv(file=\"dengue_labels_train.csv\")\n",
    "\n",
    "df_test_features <- read.csv(file=\"dengue_features_test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop week_start_date colum\n",
    "\n",
    "df_train_features$week_start_date <- NULL\n",
    "df_train_labels$week_start_date <- NULL\n",
    "\n",
    "#change Kelvin Columns to Celcius\n",
    "df_train_features$reanalysis_min_air_temp_k <- (df_train_features$reanalysis_min_air_temp_k - 273.15)\n",
    "\n",
    "df_train_features$reanalysis_max_air_temp_k <- (df_train_features$reanalysis_max_air_temp_k - 273.15)\n",
    "\n",
    "df_train_features$reanalysis_dew_point_temp_k <- (df_train_features$reanalysis_dew_point_temp_k - 273.15)\n",
    "\n",
    "df_train_features$reanalysis_air_temp_k <- (df_train_features$reanalysis_air_temp_k - 273.15)\n",
    "\n",
    "#split the data by city\n",
    "\n",
    "df_train_features_sj <- subset(df_train_features, subset=city=='sj')\n",
    "df_train_features_iq <- subset(df_train_features, subset=city=='iq')\n",
    "\n",
    "df_train_labels_sj <- subset(df_train_labels, subset=city=='sj')\n",
    "df_train_labels_iq <- subset(df_train_labels, subset=city=='iq')\n",
    "\n",
    "#drop city column\n",
    "\n",
    "df_train_features_sj <- dplyr::select(df_train_features_sj, -city)\n",
    "df_train_features_iq <- dplyr::select(df_train_features_iq, -city)\n",
    "\n",
    "#fill null values with the mean value of the column\n",
    "df_train_features_sj = na.aggregate(df_train_features_sj)\n",
    "df_train_features_iq = na.aggregate(df_train_features_iq)\n",
    "\n",
    "#drop the correlating features for the San Juan training data\n",
    "df_train_features_sj <- dplyr::select(df_train_features_sj, -reanalysis_avg_temp_k)\n",
    "df_train_features_sj <- dplyr::select(df_train_features_sj, -reanalysis_sat_precip_amt_mm)\n",
    "df_train_features_sj <- dplyr::select(df_train_features_sj, -reanalysis_specific_humidity_g_per_kg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data in range from 0 to 1\n",
    "df_train_features_sj <- apply(df_train_features_sj, MARGIN = 2, FUN = function(X) (X - min(X))/diff(range(X)))\n",
    "df_train_features_iq <- apply(df_train_features_iq, MARGIN = 2, FUN = function(X) (X - min(X))/diff(range(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x <- as.matrix(df_train_features_sj)\n",
    "y <- as.matrix(as.matrix(df_train_labels_sj[, 4])) \n",
    "\n",
    "\n",
    "## 75% of the sample size\n",
    "smp_size <- floor(0.75 * nrow(x))\n",
    "smp_size_y <- floor(0.75 * nrow(y))\n",
    "## set the seed to make your partition reproducible\n",
    "set.seed(2)\n",
    "train_ind <- sample(seq_len(nrow(x)), size = smp_size)\n",
    "train_ind_y <- sample(seq_len(nrow(y)), size = smp_size_y)\n",
    " \n",
    "x_train <- x[train_ind, ]\n",
    "x_test <- x[-train_ind, ]\n",
    "\n",
    "y_train <- y[train_ind_y, ]\n",
    "y_test <- y[-train_ind_y, ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "s <- cbind(x, total_cases = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(s)[20] <- \"total_cases\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle the data\n",
    "yourData<-s[sample(nrow(s)),]\n",
    "\n",
    "#Create 10 equally size folds\n",
    "folds <- cut(seq(1,nrow(s)),breaks=10,labels=FALSE)\n",
    "\n",
    "#Perform 10 fold cross validation\n",
    "for(i in 1:10){\n",
    "    #Segement your data by fold using the which() function \n",
    "    testIndexes <- which(folds==i,arr.ind=TRUE)\n",
    "    testData <- s[testIndexes, ]\n",
    "    trainData <- s[-testIndexes, ]\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5.30900970912277"
      ],
      "text/latex": [
       "5.30900970912277"
      ],
      "text/markdown": [
       "5.30900970912277"
      ],
      "text/plain": [
       "[1] 5.30901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ridge regression\n",
    "\n",
    "set.seed(1)\n",
    "cv.out = cv.glmnet(x, y ,alpha = 0, type.measure = \"mae\") \n",
    "bestlam = cv.out$lambda.min  \n",
    "\n",
    "ridge_mod = glmnet(x_train, \n",
    "                   y_train, \n",
    "                   alpha = 0, \n",
    "                   lambda = bestlam)\n",
    "\n",
    "ridge_pred = predict(ridge_mod, s = bestlam, newx = x_test)\n",
    "\n",
    "\n",
    "mae <- function(error) return(mean(abs(error)) )\n",
    "\n",
    "score   <-  mae(y_test - ridge_pred)\n",
    "\n",
    "sqrt(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5.28426018040131"
      ],
      "text/latex": [
       "5.28426018040131"
      ],
      "text/markdown": [
       "5.28426018040131"
      ],
      "text/plain": [
       "[1] 5.28426"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lasso regression\n",
    "\n",
    "set.seed(1)\n",
    "cv.out = cv.glmnet(x, y, alpha = 1, type.measure = \"mae\") \n",
    "\n",
    "bestlam = cv.out$lambda.min  \n",
    "\n",
    "lasso_mod = glmnet(x_train, \n",
    "                   y_train, \n",
    "                   alpha = 1, \n",
    "                   lambda = bestlam)\n",
    "lasso_pred = predict(lasso_mod, s = bestlam, newx = x_test)\n",
    "\n",
    "\n",
    "score   <-  mae(y_test - lasso_pred)\n",
    "sqrt(score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "5.40935403824811"
      ],
      "text/latex": [
       "5.40935403824811"
      ],
      "text/markdown": [
       "5.40935403824811"
      ],
      "text/plain": [
       "[1] 5.409354"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn_mod= knnreg(x_train,y_train, k = 5)\n",
    "knn_pred = predict(knn_mod, newdata = x_test)\n",
    "\n",
    "score   <-  mae(y_test - knn_pred)\n",
    "sqrt(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
